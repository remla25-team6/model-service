# ğŸ“¦ model-service

A lightweight Flask microâ€‘service that exposes a **sentimentâ€‘analysis model** through a REST API.  It belongs to the *model image* in the REMLA reference architecture and can be queried by the *appâ€‘service* or any HTTP client.

---

## âœ¨  Key features

| Feature                    | Description                                                                                                                                                    |
| -------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **`POST /predict`**        | Send raw review text â†’ receive a sentiment label *("pos"/"neg")*.                                                                                              |
| **`POST /correct`**        | Submit feedback (groundâ€‘truth sentiment) for a single review so new labels can be collected for future reâ€‘training.                                            |
| **Swagger UI**             | Selfâ€‘documenting API at `http://HOST:PORT/apidocs`.  Try endpoints directly from the browser.                                                                  |
| **Stateless Docker image** | The preâ€‘trained model and its BoW vectoriser are pulled from the *modelâ€‘training* GitHub release during the Docker build, so the final image starts instantly. |
| **Automated GHCR release** | Pushing a Git tag (e.g. `v0.1.0`) triggers a workflow that builds & pushes an image with semantic tags (`:v0.1.0`, `:0.1.latest`, `:0.latest`, `:latest`).     |

---

## ğŸ—‚  Repository layout

```text
model-service/
â”œâ”€â”€ .github/workflows/release.yml   # CI / CD pipeline
â”œâ”€â”€ dockerfile                      # Image build recipe (downloads model artefacts)
â”œâ”€â”€ requirements.txt                # Python runâ€‘time deps
â””â”€â”€ src/main/
    â””â”€â”€ flask_service.py            # Application entryâ€‘point (Flask + routes)
```

*The model artefacts (`model-<ver>.pkl`, `bow-<ver>.pkl`) are **not** stored in the repo; they are downloaded in the Docker build step from the `model-training` release that matches `ML_MODEL_VERSION`.*

---

## ğŸ  Quickâ€‘start (local dev)

> Requires Python â‰¥â€¯3.10 and `pip`.  Youâ€™ll also need the model artefacts in the working directory (download them from the corresponding GitHub release).

```bash
# 1Â Â Install dependencies
pip install -r requirements.txt
python -m nltk.downloader stopwords  # oneâ€‘time corpus fetch

# 2Â Â Download the artefacts (bash)
export VER=v0.1.0  # or whichever version you need
# via GitHubÂ CLI (recommended)
GH_REPO=remla25-team6/model-training

gh release download "$VER" -R "$GH_REPO" \
  -p "model-${VER}.pkl" \
  -p "bow-${VER}.pkl" \
  -D src/main

# â†’ files now live next to src/main/flask_service.py

# 3Â Â Run the service
export FLASK_APP=src/main/flask_service.py
flask run -p 8080      # â†’ http://localhost:8080
Â Â Run the service
```

```bash
# Query the prediction endpoint
curl -X POST http://localhost:8080/predict \
     -H "Content-Type: application/json" \
     -d '{"input":"Loved it! Amazing food."}'
# â†’ {"sentiment":"pos"}
```

---

## ğŸ³  Quickâ€‘start (Docker)

```bash
# Build image using embedded artefact download
export ML_MODEL_VERSION=v0.1.0

docker build \
  --build-arg ML_MODEL_VERSION=$ML_MODEL_VERSION \
  -t model-service:$ML_MODEL_VERSION .

docker run --rm -p 8080:8080 model-service:$ML_MODEL_VERSION
```

## ğŸ³ Pull Docker image
```
docker pull ghcr.io/remla25-team6/model-service:latest
```

---

## ğŸ›   API reference

### `POST /predict`

```jsonc
// Request
{ "input": "Terrible service, never again." }

// Response 200
{ "sentiment": "neg" }
```

| Code | Meaning      | When                                         |
| ---- | ------------ | -------------------------------------------- |
| 200  | OK           | Valid request, prediction returned.          |
| 400  | Bad Request  | Missing / malformed `input`.                 |
| 500  | Server Error | Exception during preprocessing or inference. |

---

### `POST /correct`

```jsonc
{
  "entries": {
    "input": "Food was cold but staff were friendly.",
    "truth": "neg"
  }
}
```

Returns the same review, the user label, and the model label.

---

## â™»ï¸  Release workflow (summary)

1. **Train & publish** a model in *model-training*; its release assets contain `model-<ver>.pkl` and `bow-<ver>.pkl`.
2. Tag `model-service` (`git tag v0.1.0 && git push origin v0.1.0`).
3. The workflow in `.github/workflows/release.yml` downloads the artefacts, builds the image, and pushes it to GHCR under multiple semantic tags.

The *app-service* pulls the appropriate tag (often `X.Y.latest`).

---


### AI DISCLAIMER
*This documentation has been generated with the help of ChatGPT o3.*
